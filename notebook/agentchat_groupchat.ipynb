{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_groupchat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Generated Agent Chat: Group Chat\n",
    "\n",
    "AutoGen offers conversable agents powered by LLM, tool or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation through multi-agent conversation.\n",
    "Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
    "\n",
    "This notebook is modified based on https://github.com/microsoft/FLAML/blob/4ea686af5c3e8ff24d9076a7a626c8b28ab5b1d7/notebook/autogen_multiagent_roleplay_chat.ipynb\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install:\n",
    "```bash\n",
    "pip install pyautogen\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# %pip install pyautogen~=0.2.0b4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "config_list_gpt4 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST.json\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt-4-0314\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\"],\n",
    "    },\n",
    ")\n",
    "# config_list_gpt35 = autogen.config_list_from_json(\n",
    "#     \"OAI_CONFIG_LIST\",\n",
    "#     filter_dict={\n",
    "#         \"model\": {\n",
    "#             \"gpt-3.5-turbo\",\n",
    "#             \"gpt-3.5-turbo-16k\",\n",
    "#             \"gpt-3.5-turbo-0301\",\n",
    "#             \"chatgpt-35-turbo-0301\",\n",
    "#             \"gpt-35-turbo-v0301\",\n",
    "#         },\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It first looks for environment variable \"OAI_CONFIG_LIST\" which needs to be a valid json string. If that variable is not found, it then looks for a json file named \"OAI_CONFIG_LIST\". It filters the configs by models (you can filter by other keys as well). Only the gpt-4 models are kept in the list based on the filter condition.\n",
    "\n",
    "The config list looks like the following:\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'base_url': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4-32k',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'base_url': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "]\n",
    "```\n",
    "\n",
    "You can set the value of config_list in any way you prefer. Please refer to this [notebook](https://github.com/microsoft/autogen/blob/main/notebook/oai_openai_utils.ipynb) for full code examples of the different methods."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\"config_list\": config_list_gpt4, \"cache_seed\": 42}\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "   name=\"User_proxy\",\n",
    "   system_message=\"A human admin.\",\n",
    "   code_execution_config={\"last_n_messages\": 2, \"work_dir\": \"groupchat\"},\n",
    "   human_input_mode=\"TERMINATE\"\n",
    ")\n",
    "coder = autogen.AssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "pm = autogen.AssistantAgent(\n",
    "    name=\"Product_manager\",\n",
    "    system_message=\"Creative in software product ideas.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, coder, pm], messages=[], max_round=12)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "Sure, I can help with that. \n",
      "\n",
      "First, let's search for the latest papers about GPT-4 on arXiv. For this, we will use the arXiv API. The arXiv API allows programmatic access to the arXiv's e-print content and metadata. \n",
      "\n",
      "The detailed information about a paper such as authors, published date, abstract are stored in metadata which we can fetch using this API.\n",
      "\n",
      "This Python script will use the \"Requests\" library to send an HTTP request to the arXiv API, and then parse the response using the \"feedparser\" library.\n",
      "\n",
      "You will need to have these libraries installed. If they're not installed, you can do so by running:\n",
      "\n",
      "```python\n",
      "!pip install requests feedparser\n",
      "```\n",
      "\n",
      "Now, let's execute our Python script to get the latest papers on GPT-4:\n",
      "\n",
      "```python\n",
      "# python\n",
      "\n",
      "# Required Libraries\n",
      "import requests\n",
      "import feedparser\n",
      "\n",
      "# Arxiv API Base URL\n",
      "base_url = 'http://export.arxiv.org/api/query?'\n",
      "\n",
      "# Search Query Parameters\n",
      "search_query = 'all:gpt-4'  # search for 'gpt-4' in all categories\n",
      "start = 0\n",
      "max_results = 10\n",
      "\n",
      "# Construct The Query\n",
      "query = f'{base_url}search_query={search_query}&start={start}&max_results={max_results}'\n",
      "\n",
      "# Send GET Request\n",
      "response = requests.get(query)\n",
      "\n",
      "# Parse The Response Using feedparser\n",
      "feed = feedparser.parse(response.content)\n",
      "\n",
      "# Loop Through Each Entry, And Print Out Information\n",
      "for entry in feed.entries:\n",
      "    print(f'Title: {entry.title}')\n",
      "    print(f'Published: {entry.published}')\n",
      "    print(f'Summary: {entry.summary}')\n",
      "    print('-'*50)\n",
      "```\n",
      "This script will output the title, published date, and summary for the first 10 results of the search.\n",
      "\n",
      "For the second part of your request about potential applications in software: \n",
      "\n",
      "Once we get the papers, I'll need to manually read the abstracts which are included in the 'Summary' of the feed entries. After we have this, I'll do a careful read to identify real-world applications. \n",
      "\n",
      "We'll understand more about GPT-4's potential real-world applications as we review the latest research publications. \n",
      "\n",
      "I will help complete that step after you run the above Python code as I need the information from the execution results to continue on to the next steps.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "execute_code was called without specifying a value for use_docker. Since the python docker package is not available, code will be run natively. Note: this fallback behavior is subject to change\n",
      "SIGALRM is not supported on Windows. No timeout will be enforced.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "  File \"\", line 1\n",
      "    !pip install requests feedparser\n",
      "    ^\n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "I apologize for the confusion. The exclamation mark in `!pip install requests feedparser` is not used in Python to run command line instructions. It is a feature of some Python environments such as Jupyter notebooks.\n",
      "\n",
      "The correct way to install Python packages is to use `pip install packageName` in your terminal/command prompt.\n",
      "\n",
      "To install `requests` and `feedparser` libraries you can open your terminal/command prompt and write the following:\n",
      "\n",
      "```sh\n",
      "pip install requests feedparser\n",
      "```\n",
      "\n",
      "After you've successfully installed these, you can then run the provided Python script.\n",
      "\n",
      "If you are not able to install these packages or want to install them directly via Python, then use the following Python script:\n",
      "\n",
      "```python\n",
      "# python\n",
      "\n",
      "import subprocess\n",
      "import sys\n",
      "\n",
      "def install(package):\n",
      "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
      "\n",
      "# Installing requests and feedparser\n",
      "install('requests')\n",
      "install('feedparser')\n",
      "\n",
      "# Required Libraries\n",
      "import requests\n",
      "import feedparser\n",
      "\n",
      "# Arxiv API Base URL\n",
      "base_url = 'http://export.arxiv.org/api/query?'\n",
      "\n",
      "# Search Query Parameters\n",
      "search_query = 'all:gpt-4'  # search for 'gpt-4' in all categories\n",
      "start = 0\n",
      "max_results = 10\n",
      "\n",
      "# Construct The Query\n",
      "query = f'{base_url}search_query={search_query}&start={start}&max_results={max_results}'\n",
      "\n",
      "# Send GET Request\n",
      "response = requests.get(query)\n",
      "\n",
      "# Parse The Response Using feedparser\n",
      "feed = feedparser.parse(response.content)\n",
      "\n",
      "# Loop Through Each Entry, And Print Out Information\n",
      "for entry in feed.entries:\n",
      "    print(f'Title: {entry.title}')\n",
      "    print(f'Published: {entry.published}')\n",
      "    print(f'Summary: {entry.summary}')\n",
      "    print('-'*50)\n",
      "```\n",
      "\n",
      "This script will first ensure that needed packages are installed before proceeding with fetching the papers.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is sh)...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "execute_code was called without specifying a value for use_docker. Since the python docker package is not available, code will be run natively. Note: this fallback behavior is subject to change\n",
      "SIGALRM is not supported on Windows. No timeout will be enforced.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 1 (inferred language is python)...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "execute_code was called without specifying a value for use_docker. Since the python docker package is not available, code will be run natively. Note: this fallback behavior is subject to change\n",
      "SIGALRM is not supported on Windows. No timeout will be enforced.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Requirement already satisfied: requests in c:\\users\\povelf\\appdata\\local\\miniconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: feedparser in c:\\users\\povelf\\appdata\\local\\miniconda3\\lib\\site-packages (6.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\povelf\\appdata\\local\\miniconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\povelf\\appdata\\local\\miniconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\povelf\\appdata\\local\\miniconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\povelf\\appdata\\local\\miniconda3\\lib\\site-packages (from requests) (2023.5.7)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\povelf\\appdata\\local\\miniconda3\\lib\\site-packages (from feedparser) (1.0.0)\n",
      "\n",
      "Requirement already satisfied: requests in c:\\users\\povelf\\appdata\\local\\miniconda3\\envs\\autogen\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\povelf\\appdata\\local\\miniconda3\\envs\\autogen\\lib\\site-packages (from requests) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\povelf\\appdata\\local\\miniconda3\\envs\\autogen\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\povelf\\appdata\\local\\miniconda3\\envs\\autogen\\lib\\site-packages (from requests) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\povelf\\appdata\\local\\miniconda3\\envs\\autogen\\lib\\site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: feedparser in c:\\users\\povelf\\appdata\\local\\miniconda3\\envs\\autogen\\lib\\site-packages (6.0.10)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\povelf\\appdata\\local\\miniconda3\\envs\\autogen\\lib\\site-packages (from feedparser) (1.0.0)\n",
      "Title: Can LLMs like GPT-4 outperform traditional AI tools in dementia\n",
      "  diagnosis? Maybe, but not today\n",
      "Published: 2023-06-02T12:47:45Z\n",
      "Summary: Recent investigations show that large language models (LLMs), specifically\n",
      "GPT-4, not only have remarkable capabilities in common Natural Language\n",
      "Processing (NLP) tasks but also exhibit human-level performance on various\n",
      "professional and academic benchmarks. However, whether GPT-4 can be directly\n",
      "used in practical applications and replace traditional artificial intelligence\n",
      "(AI) tools in specialized domains requires further experimental validation. In\n",
      "this paper, we explore the potential of LLMs such as GPT-4 to outperform\n",
      "traditional AI tools in dementia diagnosis. Comprehensive comparisons between\n",
      "GPT-4 and traditional AI tools are conducted to examine their diagnostic\n",
      "accuracy in a clinical setting. Experimental results on two real clinical\n",
      "datasets show that, although LLMs like GPT-4 demonstrate potential for future\n",
      "advancements in dementia diagnosis, they currently do not surpass the\n",
      "performance of traditional AI tools. The interpretability and faithfulness of\n",
      "GPT-4 are also evaluated by comparison with real doctors. We discuss the\n",
      "limitations of GPT-4 in its current state and propose future research\n",
      "directions to enhance GPT-4 in dementia diagnosis.\n",
      "--------------------------------------------------\n",
      "Title: GPT-4 Can't Reason\n",
      "Published: 2023-07-21T17:04:25Z\n",
      "Summary: GPT-4 was released in March 2023 to wide acclaim, marking a very substantial\n",
      "improvement across the board over GPT-3.5 (OpenAI's previously best model,\n",
      "which had powered the initial release of ChatGPT). However, despite the\n",
      "genuinely impressive improvement, there are good reasons to be highly skeptical\n",
      "of GPT-4's ability to reason. This position paper discusses the nature of\n",
      "reasoning; criticizes the current formulation of reasoning problems in the NLP\n",
      "community, as well as the way in which LLM reasoning performance is currently\n",
      "evaluated; introduces a small collection of 21 diverse reasoning problems; and\n",
      "performs a detailed qualitative evaluation of GPT-4's performance on those\n",
      "problems. Based on this analysis, the paper concludes that, despite its\n",
      "occasional flashes of analytical brilliance, GPT-4 at present is utterly\n",
      "incapable of reasoning.\n",
      "--------------------------------------------------\n",
      "Title: Question-Answering Approach to Evaluate Legal Summaries\n",
      "Published: 2023-09-26T15:36:29Z\n",
      "Summary: Traditional evaluation metrics like ROUGE compare lexical overlap between the\n",
      "reference and generated summaries without taking argumentative structure into\n",
      "account, which is important for legal summaries. In this paper, we propose a\n",
      "novel legal summarization evaluation framework that utilizes GPT-4 to generate\n",
      "a set of question-answer pairs that cover main points and information in the\n",
      "reference summary. GPT-4 is then used to generate answers based on the\n",
      "generated summary for the questions from the reference summary. Finally, GPT-4\n",
      "grades the answers from the reference summary and the generated summary. We\n",
      "examined the correlation between GPT-4 grading with human grading. The results\n",
      "suggest that this question-answering approach with GPT-4 can be a useful tool\n",
      "for gauging the quality of the summary.\n",
      "--------------------------------------------------\n",
      "Title: Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4\n",
      "Published: 2023-04-07T01:37:45Z\n",
      "Summary: Harnessing logical reasoning ability is a comprehensive natural language\n",
      "understanding endeavor. With the release of Generative Pretrained Transformer 4\n",
      "(GPT-4), highlighted as \"advanced\" at reasoning tasks, we are eager to learn\n",
      "the GPT-4 performance on various logical reasoning tasks. This report analyses\n",
      "multiple logical reasoning datasets, with popular benchmarks like LogiQA and\n",
      "ReClor, and newly-released datasets like AR-LSAT. We test the multi-choice\n",
      "reading comprehension and natural language inference tasks with benchmarks\n",
      "requiring logical reasoning. We further construct a logical reasoning\n",
      "out-of-distribution dataset to investigate the robustness of ChatGPT and GPT-4.\n",
      "We also make a performance comparison between ChatGPT and GPT-4. Experiment\n",
      "results show that ChatGPT performs significantly better than the RoBERTa\n",
      "fine-tuning method on most logical reasoning benchmarks. With early access to\n",
      "the GPT-4 API we are able to conduct intense experiments on the GPT-4 model.\n",
      "The results show GPT-4 yields even higher performance on most logical reasoning\n",
      "datasets. Among benchmarks, ChatGPT and GPT-4 do relatively well on well-known\n",
      "datasets like LogiQA and ReClor. However, the performance drops significantly\n",
      "when handling newly released and out-of-distribution datasets. Logical\n",
      "reasoning remains challenging for ChatGPT and GPT-4, especially on\n",
      "out-of-distribution and natural language inference datasets. We release the\n",
      "prompt-style logical reasoning datasets as a benchmark suite and name it\n",
      "LogiEval.\n",
      "--------------------------------------------------\n",
      "Title: Gpt-4: A Review on Advancements and Opportunities in Natural Language\n",
      "  Processing\n",
      "Published: 2023-05-04T22:46:43Z\n",
      "Summary: Generative Pre-trained Transformer 4 (GPT-4) is the fourth-generation\n",
      "language model in the GPT series, developed by OpenAI, which promises\n",
      "significant advancements in the field of natural language processing (NLP). In\n",
      "this research article, we have discussed the features of GPT-4, its potential\n",
      "applications, and the challenges that it might face. We have also compared\n",
      "GPT-4 with its predecessor, GPT-3. GPT-4 has a larger model size (more than one\n",
      "trillion), better multilingual capabilities, improved contextual understanding,\n",
      "and reasoning capabilities than GPT-3. Some of the potential applications of\n",
      "GPT-4 include chatbots, personal assistants, language translation, text\n",
      "summarization, and question-answering. However, GPT-4 poses several challenges\n",
      "and limitations such as computational requirements, data requirements, and\n",
      "ethical concerns.\n",
      "--------------------------------------------------\n",
      "Title: Is GPT-4 a Good Data Analyst?\n",
      "Published: 2023-05-24T11:26:59Z\n",
      "Summary: As large language models (LLMs) have demonstrated their powerful capabilities\n",
      "in plenty of domains and tasks, including context understanding, code\n",
      "generation, language generation, data storytelling, etc., many data analysts\n",
      "may raise concerns if their jobs will be replaced by AI. This controversial\n",
      "topic has drawn a lot of attention in public. However, we are still at a stage\n",
      "of divergent opinions without any definitive conclusion. Motivated by this, we\n",
      "raise the research question of \"is GPT-4 a good data analyst?\" in this work and\n",
      "aim to answer it by conducting head-to-head comparative studies. In detail, we\n",
      "regard GPT-4 as a data analyst to perform end-to-end data analysis with\n",
      "databases from a wide range of domains. We propose a framework to tackle the\n",
      "problems by carefully designing the prompts for GPT-4 to conduct experiments.\n",
      "We also design several task-specific evaluation metrics to systematically\n",
      "compare the performance between several professional human data analysts and\n",
      "GPT-4. Experimental results show that GPT-4 can achieve comparable performance\n",
      "to humans. We also provide in-depth discussions about our results to shed light\n",
      "on further studies before we reach the conclusion that GPT-4 can replace data\n",
      "analysts.\n",
      "--------------------------------------------------\n",
      "Title: Graph Neural Architecture Search with GPT-4\n",
      "Published: 2023-09-30T08:05:59Z\n",
      "Summary: Graph Neural Architecture Search (GNAS) has shown promising results in\n",
      "automatically designing graph neural networks. However, GNAS still requires\n",
      "intensive human labor with rich domain knowledge to design the search space and\n",
      "search strategy. In this paper, we integrate GPT-4 into GNAS and propose a new\n",
      "GPT-4 based Graph Neural Architecture Search method (GPT4GNAS for short). The\n",
      "basic idea of our method is to design a new class of prompts for GPT-4 to guide\n",
      "GPT-4 toward the generative task of graph neural architectures. The prompts\n",
      "consist of descriptions of the search space, search strategy, and search\n",
      "feedback of GNAS. By iteratively running GPT-4 with the prompts, GPT4GNAS\n",
      "generates more accurate graph neural networks with fast convergence.\n",
      "Experimental results show that embedding GPT-4 into GNAS outperforms the\n",
      "state-of-the-art GNAS methods.\n",
      "--------------------------------------------------\n",
      "Title: How is ChatGPT's behavior changing over time?\n",
      "Published: 2023-07-18T06:56:08Z\n",
      "Summary: GPT-3.5 and GPT-4 are the two most widely used large language model (LLM)\n",
      "services. However, when and how these models are updated over time is opaque.\n",
      "Here, we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 on\n",
      "several diverse tasks: 1) math problems, 2) sensitive/dangerous questions, 3)\n",
      "opinion surveys, 4) multi-hop knowledge-intensive questions, 5) generating\n",
      "code, 6) US Medical License tests, and 7) visual reasoning. We find that the\n",
      "performance and behavior of both GPT-3.5 and GPT-4 can vary greatly over time.\n",
      "For example, GPT-4 (March 2023) was reasonable at identifying prime vs.\n",
      "composite numbers (84% accuracy) but GPT-4 (June 2023) was poor on these same\n",
      "questions (51% accuracy). This is partly explained by a drop in GPT-4's amenity\n",
      "to follow chain-of-thought prompting. Interestingly, GPT-3.5 was much better in\n",
      "June than in March in this task. GPT-4 became less willing to answer sensitive\n",
      "questions and opinion survey questions in June than in March. GPT-4 performed\n",
      "better at multi-hop questions in June than in March, while GPT-3.5's\n",
      "performance dropped on this task. Both GPT-4 and GPT-3.5 had more formatting\n",
      "mistakes in code generation in June than in March. Overall, our findings show\n",
      "that the behavior of the \"same\" LLM service can change substantially in a\n",
      "relatively short amount of time, highlighting the need for continuous\n",
      "monitoring of LLMs.\n",
      "--------------------------------------------------\n",
      "Title: Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with\n",
      "  Code-based Self-Verification\n",
      "Published: 2023-08-15T17:58:45Z\n",
      "Summary: Recent progress in large language models (LLMs) like GPT-4 and PaLM-2 has\n",
      "brought significant advancements in addressing math reasoning problems. In\n",
      "particular, OpenAI's latest version of GPT-4, known as GPT-4 Code Interpreter,\n",
      "shows remarkable performance on challenging math datasets. In this paper, we\n",
      "explore the effect of code on enhancing LLMs' reasoning capability by\n",
      "introducing different constraints on the \\textit{Code Usage Frequency} of GPT-4\n",
      "Code Interpreter. We found that its success can be largely attributed to its\n",
      "powerful skills in generating and executing code, evaluating the output of code\n",
      "execution, and rectifying its solution when receiving unreasonable outputs.\n",
      "Based on this insight, we propose a novel and effective prompting method,\n",
      "explicit \\uline{c}ode-based \\uline{s}elf-\\uline{v}erification~(CSV), to further\n",
      "boost the mathematical reasoning potential of GPT-4 Code Interpreter. This\n",
      "method employs a zero-shot prompt on GPT-4 Code Interpreter to encourage it to\n",
      "use code to self-verify its answers. In instances where the verification state\n",
      "registers as ``False'', the model shall automatically amend its solution,\n",
      "analogous to our approach of rectifying errors during a mathematics\n",
      "examination. Furthermore, we recognize that the states of the verification\n",
      "result indicate the confidence of a solution, which can improve the\n",
      "effectiveness of majority voting. With GPT-4 Code Interpreter and CSV, we\n",
      "achieve an impressive zero-shot accuracy on MATH dataset \\textbf{(53.9\\% $\\to$\n",
      "84.3\\%)}.\n",
      "--------------------------------------------------\n",
      "Title: OpenAI Cribbed Our Tax Example, But Can GPT-4 Really Do Tax?\n",
      "Published: 2023-09-15T20:00:27Z\n",
      "Summary: The authors explain where OpenAI got the tax law example in its livestream\n",
      "demonstration of GPT-4, why GPT-4 got the wrong answer, and how it fails to\n",
      "reliably calculate taxes.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
      "\n",
      "From the abstracts of these papers based on GPT-4, we can see its potential applications in numerous software products such as:\n",
      "\n",
      "1. **Healthcare Applications**: The paper \"Can LLMs like GPT-4 outperform traditional AI tools in dementia diagnosis?\" suggests that GPT-4 could be used in healthcare applications to assist in diagnosing diseases like dementia. While the current accuracy might not surpass traditional AI tools, the potential for further improvements exists.\n",
      "\n",
      "2. **Legal Technology Tools**: The paper \"Question-Answering Approach to Evaluate Legal Summaries\" shows how GPT-4 could be utilised in legal technology platforms for generating legal documents, summaries, and executing question-answer trials for evaluating the quality of a summary.\n",
      "\n",
      "3. **Data Analytics Tools**: In the paper \"Is GPT-4 a Good Data Analyst?\", GPT-4 has been tested as a data analyst to perform end-to-end data analysis with databases. The results show that GPT-4 can achieve comparable performance to humans, suggesting its use-case in data analytics software.\n",
      "\n",
      "4. **Architectural Design Tools**: The paper \"Graph Neural Architecture Search with GPT-4\" integrates GPT-4 into Graph Neural Architecture Search to guide GPT-4 toward designing graph neural architectures, indicating a potential application in computer-aided design (CAD) software.\n",
      "\n",
      "5. **Educational Tools**: The paper \"Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification\" demonstrates GPT-4's capabilities in solving complex mathematical problems, providing an interesting use-case for educational software.\n",
      "\n",
      "6. **Tax Calculation Software**: The paper \"OpenAI Cribbed Our Tax Example, But Can GPT-4 Really Do Tax?\" indicates that, while GPT-4 might have limitations when calculating taxes, it's not entirely infeasible that the model might be improved and used for this purpose in future software solutions. \n",
      "\n",
      "Of course, further research and refinements would be necessary before GPT-4 could be effectively incorporated into these software tools, but the potential applications are wide-ranging and promising.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_proxy.initiate_chat(manager, message=\"Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\")\n",
    "# type exit to terminate the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
